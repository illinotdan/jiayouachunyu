"""
æ•°æ®åŒæ­¥ä»»åŠ¡
ç”¨äºä»å¤–éƒ¨APIè·å–å’ŒåŒæ­¥æ¯”èµ›æ•°æ®
æ”¯æŒOpenDotaã€STRATZã€Liquipediaä¸‰ä¸ªæ•°æ®æºï¼Œé‡‡ç”¨T-1æ—¶é—´ç­–ç•¥
"""

import requests
import time
from datetime import datetime, timedelta
from celery import Celery
from flask import current_app
from sqlalchemy import desc

from config.database import db
from models.content import Discussion
from models.match import Match, MatchStatus, League, Team, MatchPlayer, MatchAnalysis, HeroStats
from models.user import User
from utils.response import ApiResponse
from services.opendota_service import OpenDotaService
from services.stratz_service import StratzService
from services.liquipedia_service import LiquipediaService
from services.data_integration_service import DataIntegrationService
from services.unified_data_service import UnifiedDataService

# åˆ›å»ºCeleryå®ä¾‹
celery = Celery('dota_analysis')

# åˆå§‹åŒ–æ•°æ®æœåŠ¡
def get_data_services():
    """è·å–æ•°æ®æœåŠ¡å®ä¾‹"""
    return {
        'opendota': OpenDotaService(api_key=current_app.config.get('OPENDOTA_API_KEY')),
        'stratz': StratzService(api_key=current_app.config.get('STRATZ_API_KEY')),
        'liquipedia': LiquipediaService(),
        'integration': DataIntegrationService(
            opendota_key=current_app.config.get('OPENDOTA_API_KEY'),
            stratz_key=current_app.config.get('STRATZ_API_KEY')
        )
    }

@celery.task
def sync_all_data():
    """å®Œæ•´æ•°æ®åŒæ­¥æµæ°´çº¿ - T-1ç­–ç•¥"""
    try:
        current_app.logger.info("å¼€å§‹å®Œæ•´æ•°æ®åŒæ­¥æµæ°´çº¿...")
        
        # ä½¿ç”¨ç»Ÿä¸€æ•°æ®æœåŠ¡è¿›è¡ŒåŒæ­¥
        unified_service = UnifiedDataService()
        result = unified_service.sync_all_data()
        
        if result['success']:
            current_app.logger.info(f"ç»Ÿä¸€æ•°æ®æœåŠ¡åŒæ­¥å®Œæˆ: {result}")
            
            # è§¦å‘AIåˆ†æ
            trigger_ai_analysis.delay()
            
            return {
                'matches_synced': result.get('matches_synced', 0),
                'teams_synced': result.get('teams_synced', 0),
                'heroes_synced': result.get('heroes_synced', 0),
                'items_synced': result.get('items_synced', 0),
                'sync_time': datetime.utcnow().isoformat(),
                'source': 'unified_service'
            }
        else:
            current_app.logger.error(f"ç»Ÿä¸€æ•°æ®æœåŠ¡åŒæ­¥å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return {'error': result.get('error', 'ç»Ÿä¸€æ•°æ®æœåŠ¡åŒæ­¥å¤±è´¥')}
            
    except Exception as e:
        current_app.logger.error(f"å®Œæ•´æ•°æ®åŒæ­¥å¤±è´¥: {e}")
        return {'error': str(e)}

@celery.task
def sync_match_data():
    """åŒæ­¥æ¯”èµ›æ•°æ®ä»»åŠ¡ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
    try:
        current_app.logger.info("å¼€å§‹åŒæ­¥æ¯”èµ›æ•°æ®...")
        
        # ä½¿ç”¨T-1ç­–ç•¥
        yesterday = datetime.utcnow() - timedelta(days=1)
        start_time = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)
        end_time = yesterday.replace(hour=23, minute=59, second=59, microsecond=999999)
        
        services = get_data_services()
        synced_count = sync_t1_matches(services, start_time, end_time)
        
        current_app.logger.info(f"æ¯”èµ›æ•°æ®åŒæ­¥å®Œæˆï¼ŒåŒæ­¥äº† {synced_count} åœºæ¯”èµ›")
        return synced_count
        
    except Exception as e:
        current_app.logger.error(f"åŒæ­¥æ¯”èµ›æ•°æ®å¤±è´¥: {e}")
        return 0

def sync_basic_data(services):
    """åŒæ­¥åŸºç¡€æ•°æ®ï¼ˆè‹±é›„ã€ç‰©å“ç­‰ï¼‰"""
    try:
        current_app.logger.info("å¼€å§‹åŒæ­¥åŸºç¡€æ•°æ®...")
        
        # åŒæ­¥è‹±é›„æ•°æ®
        sync_heroes_data(services['opendota'], services['stratz'])
        
        # åŒæ­¥ç‰©å“æ•°æ®
        sync_items_data(services['stratz'])
        
        current_app.logger.info("åŸºç¡€æ•°æ®åŒæ­¥å®Œæˆ")
        
    except Exception as e:
        current_app.logger.error(f"åŒæ­¥åŸºç¡€æ•°æ®å¤±è´¥: {e}")

def sync_heroes_data(opendota_service, stratz_service):
    """åŒæ­¥è‹±é›„æ•°æ®"""
    try:
        from models.match import Hero
        
        # ä»OpenDotaè·å–è‹±é›„åˆ—è¡¨
        opendota_heroes = opendota_service.get_heroes()
        
        # ä»STRATZè·å–è‹±é›„åˆ—è¡¨
        stratz_heroes = stratz_service.get_heroes('detailed')
        
        current_app.logger.info(f"OpenDotaè‹±é›„æ•°: {len(opendota_heroes)}, STRATZè‹±é›„æ•°: {len(stratz_heroes)}")
        
        # åˆå¹¶å’ŒåŒæ­¥è‹±é›„æ•°æ®
        for hero_data in opendota_heroes:
            hero_id = hero_data.get('id')
            if not hero_id:
                continue
                
            # æ£€æŸ¥è‹±é›„æ˜¯å¦å·²å­˜åœ¨
            existing_hero = Hero.query.filter_by(id=hero_id).first()
            
            if not existing_hero:
                hero = Hero(
                    id=hero_id,
                    name=hero_data.get('name', ''),
                    display_name=hero_data.get('localized_name', ''),
                    primary_attribute=Hero.Attribute.STRENGTH,  # é»˜è®¤å€¼ï¼Œéœ€è¦ä»å…¶ä»–æºè·å–
                    roles=hero_data.get('roles', []),
                    image_url=f"https://api.opendota.com{hero_data.get('img', '')}",
                    icon_url=f"https://api.opendota.com{hero_data.get('icon', '')}",
                    complexity=1,
                    is_active=True
                )
                db.session.add(hero)
        
        db.session.commit()
        current_app.logger.info("è‹±é›„æ•°æ®åŒæ­¥å®Œæˆ")
        
    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"åŒæ­¥è‹±é›„æ•°æ®å¤±è´¥: {e}")

def sync_items_data(stratz_service):
    """åŒæ­¥ç‰©å“æ•°æ®"""
    try:
        # ä»STRATZè·å–ç‰©å“æ•°æ®
        items = stratz_service.get_items()
        
        current_app.logger.info(f"è·å–åˆ° {len(items)} ä¸ªç‰©å“")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ ç‰©å“æ•°æ®æ¨¡å‹å’ŒåŒæ­¥é€»è¾‘
        # æš‚æ—¶è®°å½•æ—¥å¿—
        
    except Exception as e:
        current_app.logger.error(f"åŒæ­¥ç‰©å“æ•°æ®å¤±è´¥: {e}")

def sync_t1_matches(services, start_time, end_time):
    """åŒæ­¥T-1æ¯”èµ›æ•°æ®"""
    try:
        current_app.logger.info(f"å¼€å§‹åŒæ­¥T-1æ¯”èµ›æ•°æ®: {start_time} åˆ° {end_time}")
        
        synced_count = 0
        
        # 1. ä»OpenDotaè·å–èŒä¸šæ¯”èµ›
        opendota_matches = fetch_matches_from_opendota(services['opendota'], start_time, end_time)
        current_app.logger.info(f"OpenDotaè·å–åˆ° {len(opendota_matches)} åœºæ¯”èµ›")
        
        for match_data in opendota_matches:
            if sync_single_match(match_data, services):
                synced_count += 1
        
        # 2. ä»STRATZè·å–è¡¥å……æ•°æ®
        # è¿™é‡Œå¯ä»¥æ·»åŠ STRATZç‰¹æœ‰çš„æ¯”èµ›æ•°æ®è·å–é€»è¾‘
        
        current_app.logger.info(f"T-1æ¯”èµ›æ•°æ®åŒæ­¥å®Œæˆï¼Œå…±åŒæ­¥ {synced_count} åœºæ¯”èµ›")
        return synced_count
        
    except Exception as e:
        current_app.logger.error(f"åŒæ­¥T-1æ¯”èµ›æ•°æ®å¤±è´¥: {e}")
        return 0

def sync_teams_and_players(services):
    """åŒæ­¥æˆ˜é˜Ÿå’Œé€‰æ‰‹ä¿¡æ¯"""
    try:
        current_app.logger.info("å¼€å§‹åŒæ­¥æˆ˜é˜Ÿå’Œé€‰æ‰‹ä¿¡æ¯...")
        
        synced_count = 0
        
        # 1. ä»Liquipediaè·å–çƒ­é—¨æˆ˜é˜Ÿ
        popular_teams = [
            'Team Spirit', 'PSG.LGD', 'OG', 'Team Secret', 'Evil Geniuses',
            'Virtus.pro', 'T1', 'Team Liquid', 'Fnatic', 'Alliance'
        ]
        
        for team_name in popular_teams:
            team_info = services['liquipedia'].get_team_info(team_name)
            if team_info and sync_team_info(team_info):
                synced_count += 1
                
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(2)
        
        current_app.logger.info(f"æˆ˜é˜Ÿå’Œé€‰æ‰‹ä¿¡æ¯åŒæ­¥å®Œæˆï¼Œå…±åŒæ­¥ {synced_count} ä¸ªæˆ˜é˜Ÿ")
        return synced_count
        
    except Exception as e:
        current_app.logger.error(f"åŒæ­¥æˆ˜é˜Ÿå’Œé€‰æ‰‹ä¿¡æ¯å¤±è´¥: {e}")
        return 0

def sync_team_info(team_info):
    """åŒæ­¥å•ä¸ªæˆ˜é˜Ÿä¿¡æ¯"""
    try:
        team_name = team_info.get('name')
        if not team_name:
            return False
        
        # æ£€æŸ¥æˆ˜é˜Ÿæ˜¯å¦å·²å­˜åœ¨
        existing_team = Team.query.filter_by(name=team_name).first()
        
        if not existing_team:
            team = Team(
                name=team_name,
                tag=team_name[:3].upper(),
                logo_url=team_info.get('logo_url'),
                region=team_info.get('region'),
                description=team_info.get('description'),
                website_url=team_info.get('url'),
                social_links=team_info.get('social_links', {}),
                is_active=True
            )
            db.session.add(team)
        else:
            # æ›´æ–°ç°æœ‰æˆ˜é˜Ÿä¿¡æ¯
            existing_team.logo_url = team_info.get('logo_url') or existing_team.logo_url
            existing_team.region = team_info.get('region') or existing_team.region
            existing_team.description = team_info.get('description') or existing_team.description
            existing_team.social_links = team_info.get('social_links', existing_team.social_links)
        
        db.session.commit()
        return True
        
    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"åŒæ­¥æˆ˜é˜Ÿä¿¡æ¯å¤±è´¥ {team_info.get('name', 'Unknown')}: {e}")
        return False

def validate_and_clean_data():
    """æ•°æ®æ¸…æ´—å’ŒéªŒè¯"""
    try:
        current_app.logger.info("å¼€å§‹æ•°æ®æ¸…æ´—å’ŒéªŒè¯...")
        
        validation_result = {
            'orphan_matches': 0,
            'missing_logos': 0,
            'data_quality_issues': []
        }
        
        # æ£€æŸ¥å­¤å„¿æ¯”èµ›ï¼ˆç¼ºå°‘æˆ˜é˜Ÿä¿¡æ¯ï¼‰
        orphan_matches = Match.query.filter(
            (Match.radiant_team_id.is_(None)) | (Match.dire_team_id.is_(None))
        ).count()
        validation_result['orphan_matches'] = orphan_matches
        
        # æ£€æŸ¥ç¼ºå¤±Logoçš„æˆ˜é˜Ÿ
        teams_without_logo = Team.query.filter(
            (Team.logo_url.is_(None)) | (Team.logo_url == '')
        ).count()
        validation_result['missing_logos'] = teams_without_logo
        
        # è®°å½•æ•°æ®è´¨é‡é—®é¢˜
        if orphan_matches > 0:
            validation_result['data_quality_issues'].append(f"{orphan_matches} åœºæ¯”èµ›ç¼ºå°‘æˆ˜é˜Ÿä¿¡æ¯")
        
        if teams_without_logo > 0:
            validation_result['data_quality_issues'].append(f"{teams_without_logo} ä¸ªæˆ˜é˜Ÿç¼ºå°‘Logo")
        
        current_app.logger.info(f"æ•°æ®éªŒè¯å®Œæˆ: {validation_result}")
        return validation_result
        
    except Exception as e:
        current_app.logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
        return {'error': str(e)}

def fetch_matches_from_opendota(opendota_service, start_time, end_time):
    """ä»OpenDotaè·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ¯”èµ›"""
    try:
        # è·å–èŒä¸šæ¯”èµ›
        pro_matches = opendota_service.get_pro_matches(limit=200)
        
        # è¿‡æ»¤æ—¶é—´èŒƒå›´
        filtered_matches = []
        for match in pro_matches:
            match_time = datetime.utcfromtimestamp(match.get('start_time', 0))
            if start_time <= match_time <= end_time:
                filtered_matches.append(match)
        
        return filtered_matches
        
    except Exception as e:
        current_app.logger.error(f"ä»OpenDotaè·å–æ¯”èµ›å¤±è´¥: {e}")
        return []

@celery.task
def trigger_ai_analysis():
    """è§¦å‘AIåˆ†æä»»åŠ¡"""
    try:
        current_app.logger.info("è§¦å‘AIåˆ†æä»»åŠ¡...")
        
        # è¿™é‡Œå°†è°ƒç”¨AIåˆ†ææœåŠ¡
        # æš‚æ—¶è®°å½•æ—¥å¿—
        current_app.logger.info("AIåˆ†æä»»åŠ¡å·²è§¦å‘")
        
        return {'status': 'triggered', 'time': datetime.utcnow().isoformat()}
        
    except Exception as e:
        current_app.logger.error(f"è§¦å‘AIåˆ†æå¤±è´¥: {e}")
        return {'error': str(e)}

def fetch_recent_matches_from_opendota():
    """ä»OpenDota APIè·å–æœ€è¿‘æ¯”èµ›"""
    try:
        api_key = current_app.config.get('OPENDOTA_API_KEY')
        
        # è·å–èŒä¸šæ¯”èµ›
        url = "https://api.opendota.com/api/proMatches"
        headers = {}
        
        if api_key:
            headers['Authorization'] = f'Bearer {api_key}'
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        matches = response.json()
        
        # åªå¤„ç†æœ€è¿‘24å°æ—¶çš„æ¯”èµ›
        recent_matches = []
        cutoff_time = datetime.utcnow() - timedelta(hours=24)
        
        for match in matches:
            match_time = datetime.utcfromtimestamp(match['start_time'])
            if match_time >= cutoff_time:
                recent_matches.append(match)
        
        return recent_matches[:50]  # é™åˆ¶æ•°é‡
        
    except Exception as e:
        current_app.logger.error(f"è·å–OpenDotaæ•°æ®å¤±è´¥: {e}")
        return []

def sync_single_match(match_data, services=None):
    """åŒæ­¥å•åœºæ¯”èµ›æ•°æ®"""
    try:
        match_id = str(match_data['match_id'])
        
        # æ£€æŸ¥æ¯”èµ›æ˜¯å¦å·²å­˜åœ¨
        existing_match = Match.query.filter_by(match_id=match_id).first()
        if existing_match:
            return False
        
        # è·å–æˆ–åˆ›å»ºæˆ˜é˜Ÿ
        radiant_team = get_or_create_team(match_data.get('radiant_team'))
        dire_team = get_or_create_team(match_data.get('dire_team'))
        
        # è·å–æˆ–åˆ›å»ºè”èµ›
        league = get_or_create_league(match_data.get('league'))
        
        # åˆ›å»ºæ¯”èµ›è®°å½•
        match = Match(
            match_id=match_id,
            league_id=league.id if league else None,
            radiant_team_id=radiant_team.id if radiant_team else None,
            dire_team_id=dire_team.id if dire_team else None,
            radiant_score=match_data.get('radiant_score', 0),
            dire_score=match_data.get('dire_score', 0),
            radiant_win=match_data.get('radiant_win'),
            duration=match_data.get('duration'),
            start_time=datetime.utcfromtimestamp(match_data['start_time']),
            status=MatchStatus.FINISHED,
            patch_version=match_data.get('patch'),
            region=match_data.get('region')
        )
        
        db.session.add(match)
        db.session.flush()  # è·å–match.id
        
        # è·å–è¯¦ç»†æ¯”èµ›æ•°æ®
        if services and 'integration' in services:
            # ä½¿ç”¨æ•°æ®æ•´åˆæœåŠ¡è·å–å¢å¼ºæ•°æ®
            enhanced_data = services['integration'].get_enhanced_match_data(int(match_id))
            if enhanced_data:
                sync_enhanced_match_data(match.id, enhanced_data)
        else:
            # ä½¿ç”¨åŸæœ‰æ–¹å¼è·å–è¯¦ç»†æ•°æ®
            detailed_data = fetch_match_details(match_id)
            if detailed_data:
                sync_match_players(match.id, detailed_data)
                sync_match_analysis(match.id, detailed_data)
        
        db.session.commit()
        return True
        
    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"åŒæ­¥æ¯”èµ› {match_data.get('match_id')} å¤±è´¥: {e}")
        return False

def sync_enhanced_match_data(match_id, enhanced_data):
    """åŒæ­¥å¢å¼ºç‰ˆæ¯”èµ›æ•°æ®"""
    try:
        # å¤„ç†OpenDotaæ•°æ®
        opendota_data = enhanced_data.get('opendota_data', {})
        if opendota_data:
            sync_match_players(match_id, opendota_data)
            sync_match_analysis(match_id, opendota_data)
        
        # å¤„ç†STRATZæ•°æ®
        stratz_data = enhanced_data.get('stratz_data', {})
        if stratz_data:
            # è¿™é‡Œå¯ä»¥æ·»åŠ STRATZç‰¹æœ‰çš„æ•°æ®å¤„ç†é€»è¾‘
            current_app.logger.info(f"å¤„ç†STRATZæ•°æ®: {match_id}")
        
        # ä¿å­˜æ•°æ®è´¨é‡è¯„ä¼°
        data_quality = enhanced_data.get('data_quality', {})
        current_app.logger.info(f"æ¯”èµ› {match_id} æ•°æ®è´¨é‡: {data_quality}")
        
    except Exception as e:
        current_app.logger.error(f"åŒæ­¥å¢å¼ºç‰ˆæ¯”èµ›æ•°æ®å¤±è´¥ {match_id}: {e}")

def get_or_create_team(team_data):
    """è·å–æˆ–åˆ›å»ºæˆ˜é˜Ÿ"""
    if not team_data or not team_data.get('name'):
        return None
    
    team = Team.query.filter_by(name=team_data['name']).first()
    
    if not team:
        team = Team(
            name=team_data['name'],
            tag=team_data.get('tag', team_data['name'][:3].upper()),
            logo_url=team_data.get('logo_url')
        )
        db.session.add(team)
        db.session.flush()
    
    return team

def get_or_create_league(league_data):
    """è·å–æˆ–åˆ›å»ºè”èµ›"""
    if not league_data or not league_data.get('name'):
        return None
    
    league = League.query.filter_by(name=league_data['name']).first()
    
    if not league:
        league = League(
            name=league_data['name'],
            tier=league_data.get('tier', 3)
        )
        db.session.add(league)
        db.session.flush()
    
    return league

def fetch_match_details(match_id):
    """è·å–æ¯”èµ›è¯¦ç»†æ•°æ®"""
    try:
        api_key = current_app.config.get('OPENDOTA_API_KEY')
        
        url = f"https://api.opendota.com/api/matches/{match_id}"
        headers = {}
        
        if api_key:
            headers['Authorization'] = f'Bearer {api_key}'
        
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        return response.json()
        
    except Exception as e:
        current_app.logger.error(f"è·å–æ¯”èµ›è¯¦æƒ…å¤±è´¥ {match_id}: {e}")
        return None

def sync_match_players(match_id, match_data):
    """åŒæ­¥æ¯”èµ›é€‰æ‰‹æ•°æ®"""
    try:
        players_data = match_data.get('players', [])
        
        for i, player_data in enumerate(players_data):
            team_side = 'radiant' if i < 5 else 'dire'
            
            match_player = MatchPlayer(
                match_id=match_id,
                account_id=str(player_data.get('account_id', 0)),
                player_name=player_data.get('personaname', f'Player {i+1}'),
                team_side=team_side,
                hero_id=player_data.get('hero_id', 1),
                kills=player_data.get('kills', 0),
                deaths=player_data.get('deaths', 0),
                assists=player_data.get('assists', 0),
                last_hits=player_data.get('last_hits', 0),
                denies=player_data.get('denies', 0),
                gpm=player_data.get('gold_per_min', 0),
                xpm=player_data.get('xp_per_min', 0),
                net_worth=player_data.get('net_worth', 0),
                hero_damage=player_data.get('hero_damage', 0),
                tower_damage=player_data.get('tower_damage', 0),
                hero_healing=player_data.get('hero_healing', 0),
                level=player_data.get('level', 1),
                items=player_data.get('item_0', [])  # ç®€åŒ–å¤„ç†
            )
            
            db.session.add(match_player)
        
    except Exception as e:
        current_app.logger.error(f"åŒæ­¥é€‰æ‰‹æ•°æ®å¤±è´¥: {e}")

def sync_match_analysis(match_id, match_data):
    """åŒæ­¥æ¯”èµ›åˆ†ææ•°æ®"""
    try:
        # æå–å…³é”®æ—¶åˆ»
        key_moments = []
        objectives = match_data.get('objectives', [])
        
        for obj in objectives[:10]:  # é™åˆ¶æ•°é‡
            if obj.get('type') in ['CHAT_MESSAGE_FIRSTBLOOD', 'CHAT_MESSAGE_AEGIS']:
                key_moments.append({
                    'time': f"{obj.get('time', 0) // 60}:{obj.get('time', 0) % 60:02d}",
                    'event': obj.get('type', 'Unknown'),
                    'description': f"ç¬¬{obj.get('time', 0) // 60}åˆ†é’Ÿé‡è¦äº‹ä»¶"
                })
        
        # æ‰¾å‡ºMVPï¼ˆæœ€é«˜KDAçš„é€‰æ‰‹ï¼‰
        mvp_player = None
        best_kda = 0
        
        for player in match_data.get('players', []):
            kills = player.get('kills', 0)
            deaths = max(player.get('deaths', 1), 1)  # é¿å…é™¤é›¶
            assists = player.get('assists', 0)
            kda = (kills + assists) / deaths
            
            if kda > best_kda:
                best_kda = kda
                mvp_player = player.get('personaname', 'Unknown')
        
        # åˆ›å»ºåˆ†æè®°å½•
        analysis = MatchAnalysis(
            match_id=match_id,
            key_moments=key_moments,
            mvp_player=mvp_player,
            turning_point="æ¯”èµ›å…³é”®è½¬æŠ˜ç‚¹åˆ†æ",
            prediction_confidence=85,
            prediction_reasoning="åŸºäºæ•°æ®åˆ†æçš„é¢„æµ‹"
        )
        
        db.session.add(analysis)
        
    except Exception as e:
        current_app.logger.error(f"åŒæ­¥åˆ†ææ•°æ®å¤±è´¥: {e}")

@celery.task
def update_hero_statistics():
    """æ›´æ–°è‹±é›„ç»Ÿè®¡æ•°æ®ä»»åŠ¡"""
    try:
        current_app.logger.info("å¼€å§‹æ›´æ–°è‹±é›„ç»Ÿè®¡...")
        
        from models.match import HeroStats, Hero
        
        # è·å–æ‰€æœ‰è‹±é›„
        heroes = Hero.query.filter_by(is_active=True).all()
        
        for hero in heroes:
            # è®¡ç®—ä¸åŒæ—¶é—´å‘¨æœŸçš„ç»Ÿè®¡
            for period in ['week', 'month', 'all']:
                calculate_hero_stats_for_period(hero.id, period)
        
        current_app.logger.info("è‹±é›„ç»Ÿè®¡æ›´æ–°å®Œæˆ")
        return True
        
    except Exception as e:
        current_app.logger.error(f"æ›´æ–°è‹±é›„ç»Ÿè®¡å¤±è´¥: {e}")
        return False

def calculate_hero_stats_for_period(hero_id, period):
    """è®¡ç®—æŒ‡å®šè‹±é›„åœ¨æŒ‡å®šæ—¶æœŸçš„ç»Ÿè®¡æ•°æ®"""
    try:
        # è®¡ç®—æ—¶é—´èŒƒå›´
        if period == 'week':
            start_date = datetime.utcnow() - timedelta(days=7)
            period_enum = HeroStats.Period.WEEK
        elif period == 'month':
            start_date = datetime.utcnow() - timedelta(days=30)
            period_enum = HeroStats.Period.MONTH
        else:
            start_date = None
            period_enum = HeroStats.Period.ALL
        
        # æ„å»ºæŸ¥è¯¢
        from models.match import MatchPlayer, Match
        
        query = db.session.query(MatchPlayer).join(Match).filter(
            MatchPlayer.hero_id == hero_id,
            Match.status == MatchStatus.FINISHED
        )
        
        if start_date:
            query = query.filter(Match.start_time >= start_date)
        
        player_performances = query.all()
        
        if not player_performances:
            return
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        total_matches = len(player_performances)
        wins = sum(1 for p in player_performances if 
                  (p.team_side.value == 'radiant' and p.match.radiant_win) or
                  (p.team_side.value == 'dire' and not p.match.radiant_win))
        
        win_rate = (wins / total_matches * 100) if total_matches > 0 else 0
        
        # è®¡ç®—å¹³å‡æ•°æ®
        avg_kda = sum((p.kills + p.assists) / max(p.deaths, 1) for p in player_performances) / total_matches
        avg_gpm = sum(p.gpm for p in player_performances) / total_matches
        avg_xpm = sum(p.xpm for p in player_performances) / total_matches
        
        # æ›´æ–°æˆ–åˆ›å»ºç»Ÿè®¡è®°å½•
        hero_stat = HeroStats.query.filter_by(
            hero_id=hero_id,
            period_type=period_enum,
            tier_filter=HeroStats.Tier.ALL
        ).first()
        
        if not hero_stat:
            hero_stat = HeroStats(
                hero_id=hero_id,
                period_type=period_enum,
                tier_filter=HeroStats.Tier.ALL
            )
            db.session.add(hero_stat)
        
        # æ›´æ–°æ•°æ®
        hero_stat.total_matches = total_matches
        hero_stat.wins = wins
        hero_stat.win_rate = round(win_rate, 2)
        hero_stat.avg_kda = round(avg_kda, 2)
        hero_stat.avg_gpm = int(avg_gpm)
        hero_stat.avg_xpm = int(avg_xpm)
        hero_stat.calculated_at = datetime.utcnow()
        
        db.session.commit()
        
    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"è®¡ç®—è‹±é›„ {hero_id} ç»Ÿè®¡å¤±è´¥: {e}")

@celery.task
def resolve_match_predictions():
    """è§£ææ¯”èµ›é¢„æµ‹ç»“æœä»»åŠ¡"""
    try:
        current_app.logger.info("å¼€å§‹è§£æé¢„æµ‹ç»“æœ...")
        
        from models.match import ExpertPrediction
        
        # è·å–å·²ç»“æŸä½†é¢„æµ‹æœªè§£æçš„æ¯”èµ›
        finished_matches = Match.query.filter(
            Match.status == MatchStatus.FINISHED,
            Match.end_time.isnot(None)
        ).join(ExpertPrediction).filter(
            ExpertPrediction.result == 'pending'
        ).distinct().all()
        
        resolved_count = 0
        for match in finished_matches:
            ExpertPrediction.resolve_predictions_for_match(match.id)
            resolved_count += 1
        
        current_app.logger.info(f"é¢„æµ‹ç»“æœè§£æå®Œæˆï¼Œå¤„ç†äº† {resolved_count} åœºæ¯”èµ›")
        return resolved_count
        
    except Exception as e:
        current_app.logger.error(f"è§£æé¢„æµ‹ç»“æœå¤±è´¥: {e}")
        return 0

@celery.task
def calculate_daily_statistics():
    """è®¡ç®—æ¯æ—¥ç»Ÿè®¡æ•°æ®ä»»åŠ¡"""
    try:
        from models.audit import DailyStats
        from datetime import date
        
        yesterday = date.today() - timedelta(days=1)
        
        # è®¡ç®—æ˜¨å¤©çš„ç»Ÿè®¡æ•°æ®
        daily_stat = DailyStats.calculate_daily_stats(yesterday)
        
        if daily_stat:
            current_app.logger.info(f"æ¯æ—¥ç»Ÿè®¡è®¡ç®—å®Œæˆ: {yesterday}")
            return True
        else:
            current_app.logger.error(f"æ¯æ—¥ç»Ÿè®¡è®¡ç®—å¤±è´¥: {yesterday}")
            return False
            
    except Exception as e:
        current_app.logger.error(f"è®¡ç®—æ¯æ—¥ç»Ÿè®¡å¤±è´¥: {e}")
        return False

@celery.task
def cleanup_expired_data():
    """æ¸…ç†è¿‡æœŸæ•°æ®ä»»åŠ¡"""
    try:
        from models.user import UserSession
        from models.notification import Notification
        from models.content import ContentView
        
        # æ¸…ç†è¿‡æœŸä¼šè¯
        expired_sessions = UserSession.cleanup_expired()
        
        # æ¸…ç†æ—§é€šçŸ¥
        deleted_notifications = Notification.cleanup_old_notifications(days=30)
        
        # æ¸…ç†æ—§æµè§ˆè®°å½•
        thirty_days_ago = datetime.utcnow() - timedelta(days=30)
        deleted_views = ContentView.query.filter(
            ContentView.created_at < thirty_days_ago
        ).delete()
        
        db.session.commit()
        
        current_app.logger.info(
            f"æ•°æ®æ¸…ç†å®Œæˆ - ä¼šè¯: {expired_sessions}, "
            f"é€šçŸ¥: {deleted_notifications}, æµè§ˆè®°å½•: {deleted_views}"
        )
        
        return {
            'sessions': expired_sessions,
            'notifications': deleted_notifications,
            'views': deleted_views
        }
        
    except Exception as e:
        db.session.rollback()
        current_app.logger.error(f"æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {e}")
        return None

@celery.task
def send_digest_emails():
    """å‘é€æ¯æ—¥æ‘˜è¦é‚®ä»¶ä»»åŠ¡"""
    try:
        from models.user import User
        from flask_mail import Message, Mail
        
        # è·å–è®¢é˜…äº†é‚®ä»¶æ‘˜è¦çš„ç”¨æˆ·
        users = User.query.filter_by(is_active=True).all()
        
        # è·å–æ˜¨å¤©çš„çƒ­é—¨å†…å®¹
        yesterday = datetime.utcnow() - timedelta(days=1)
        
        hot_discussions = Discussion.query.filter(
            Discussion.created_at >= yesterday
        ).order_by(desc(Discussion.view_count)).limit(5).all()
        
        sent_count = 0
        
        for user in users:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å¯ç”¨äº†é‚®ä»¶é€šçŸ¥
            if user.profile and not user.profile.notification_settings.get('emailNotifications', True):
                continue
            
            try:
                send_daily_digest(user, hot_discussions)
                sent_count += 1
                
                # é¿å…å‘é€è¿‡å¿«
                time.sleep(0.1)
                
            except Exception as e:
                current_app.logger.error(f"å‘é€æ‘˜è¦é‚®ä»¶ç»™ {user.email} å¤±è´¥: {e}")
        
        current_app.logger.info(f"æ¯æ—¥æ‘˜è¦é‚®ä»¶å‘é€å®Œæˆï¼Œå‘é€äº† {sent_count} å°é‚®ä»¶")
        return sent_count
        
    except Exception as e:
        current_app.logger.error(f"å‘é€æ‘˜è¦é‚®ä»¶ä»»åŠ¡å¤±è´¥: {e}")
        return 0

def send_daily_digest(user, hot_discussions):
    """å‘é€å•ä¸ªç”¨æˆ·çš„æ¯æ—¥æ‘˜è¦"""
    from flask_mail import Message, Mail
    
    mail = Mail(current_app)
    
    # æ„å»ºé‚®ä»¶å†…å®¹
    html_content = f"""
    <div style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; background: #1a1f2e; color: #e2e8f0; padding: 20px;">
        <h1 style="color: #4299e1; text-align: center;">ğŸ® åˆ€å¡”è§£ææ¯æ—¥æ‘˜è¦</h1>
        
        <p>Hi {user.username},</p>
        
        <p>ä»¥ä¸‹æ˜¯æ˜¨æ—¥çš„çƒ­é—¨è®¨è®ºï¼š</p>
        
        <div style="margin: 20px 0;">
            {''.join([
                f'''
                <div style="background: #2d3748; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #4299e1;">
                    <h3 style="margin: 0 0 10px 0; color: #ffffff;">{discussion.title}</h3>
                    <p style="margin: 0; color: #a0aec0; font-size: 14px;">
                        ğŸ‘ï¸ {discussion.view_count} æµè§ˆ | ğŸ‘ {discussion.like_count} ç‚¹èµ | ğŸ’¬ {discussion.reply_count} å›å¤
                    </p>
                </div>
                '''
                for discussion in hot_discussions
            ])}
        </div>
        
        <div style="text-align: center; margin: 30px 0;">
            <a href="http://dotaanalysis.com" style="background: #4299e1; color: white; padding: 12px 24px; text-decoration: none; border-radius: 6px;">
                è®¿é—®åˆ€å¡”è§£æ
            </a>
        </div>
        
        <hr style="border: none; border-top: 1px solid #2d3748; margin: 20px 0;">
        
        <p style="color: #718096; font-size: 12px; text-align: center;">
            ä¸æƒ³æ¥æ”¶æ¯æ—¥æ‘˜è¦ï¼Ÿ<a href="http://dotaanalysis.com/settings" style="color: #4299e1;">ç‚¹å‡»è¿™é‡Œ</a>ä¿®æ”¹è®¾ç½®
        </p>
    </div>
    """
    
    msg = Message(
        subject='[åˆ€å¡”è§£æ] æ¯æ—¥çƒ­é—¨æ‘˜è¦',
        recipients=[user.email],
        html=html_content
    )
    
    mail.send(msg)

# Celeryå®šæ—¶ä»»åŠ¡é…ç½®
@celery.on_after_configure.connect
def setup_periodic_tasks(sender, **kwargs):
    """è®¾ç½®å®šæ—¶ä»»åŠ¡ - é‡‡ç”¨T-1ç­–ç•¥"""
    from celery.schedules import crontab
    
    # æ¯å¤©å‡Œæ™¨1ç‚¹æ‰§è¡Œå®Œæ•´æ•°æ®åŒæ­¥ï¼ˆT-1ç­–ç•¥ï¼‰
    sender.add_periodic_task(
        crontab(hour=1, minute=0),
        sync_all_data.s(),
        name='daily T-1 data sync'
    )
    
    # æ¯å¤©å‡Œæ™¨2ç‚¹è®¡ç®—ç»Ÿè®¡æ•°æ®
    sender.add_periodic_task(
        crontab(hour=2, minute=0),
        calculate_daily_statistics.s(),
        name='calculate daily stats'
    )
    
    # æ¯å¤©å‡Œæ™¨3ç‚¹æ›´æ–°è‹±é›„ç»Ÿè®¡
    sender.add_periodic_task(
        crontab(hour=3, minute=0),
        update_hero_statistics.s(),
        name='update hero stats'
    )
    
    # æ¯å¤©å‡Œæ™¨4ç‚¹æ¸…ç†è¿‡æœŸæ•°æ®
    sender.add_periodic_task(
        crontab(hour=4, minute=0),
        cleanup_expired_data.s(),
        name='cleanup expired data'
    )
    
    # æ¯30åˆ†é’Ÿè§£æé¢„æµ‹ç»“æœï¼ˆä¿æŒå®æ—¶æ€§ï¼‰
    sender.add_periodic_task(
        1800.0,  # 30åˆ†é’Ÿ
        resolve_match_predictions.s(),
        name='resolve predictions'
    )
    
    # æ¯å¤©æ—©ä¸Š8ç‚¹å‘é€æ‘˜è¦é‚®ä»¶
    sender.add_periodic_task(
        crontab(hour=8, minute=0),
        send_digest_emails.s(),
        name='send daily digest'
    )
    
    # å¤‡ç”¨ï¼šæ¯4å°æ—¶æ‰§è¡Œä¸€æ¬¡å¢é‡åŒæ­¥ï¼ˆä»…æ¯”èµ›æ•°æ®ï¼‰
    sender.add_periodic_task(
        14400.0,  # 4å°æ—¶
        sync_match_data.s(),
        name='incremental match sync'
    )
