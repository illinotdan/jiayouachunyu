# éƒ¨ç½²æŒ‡å—

## ç¯å¢ƒè¦æ±‚

### å¼€å‘ç¯å¢ƒ
- Node.js 18+ å’Œ npm
- Python 3.9+ å’Œ pip
- PostgreSQL 14+
- Redis 6+
- Git
- Git LFS (ç”¨äºAIæ¨¡å‹æ–‡ä»¶)

### ç”Ÿäº§ç¯å¢ƒ
- Docker 20.10+
- Docker Compose 2.0+
- åŸŸåå’ŒSSLè¯ä¹¦
- äº‘æœåŠ¡æä¾›å•†è´¦æˆ·
- Kubernetes (å¯é€‰ï¼Œç”¨äºå¤§è§„æ¨¡éƒ¨ç½²)
- Git LFS (ç”¨äºAIæ¨¡å‹æ–‡ä»¶)
- GPUæ”¯æŒ (å¯é€‰ï¼Œç”¨äºAIæ¨¡å‹åŠ é€Ÿ)

### AIæ¨¡å‹ç¯å¢ƒè¦æ±‚
- TensorFlow 2.8+ æˆ– PyTorch 1.12+
- CUDA 11.7+ (GPUåŠ é€Ÿ)
- æ¨¡å‹æ–‡ä»¶å­˜å‚¨ç©ºé—´: 2GB+
- å†…å­˜è¦æ±‚: 4GB+ (CPUæ¨¡å¼) / 8GB+ (GPUæ¨¡å¼)

## æœ¬åœ°å¼€å‘éƒ¨ç½²

### 1. å…‹éš†é¡¹ç›®
```bash
git clone <repository-url>
cd dota2-analyzer
```

### 2. ç¯å¢ƒå‡†å¤‡
```bash
# åˆå§‹åŒ–Git LFS
git lfs install
git lfs pull

# å®‰è£…å‰ç«¯ä¾èµ–
cd frontend
npm install

# å®‰è£…åç«¯ä¾èµ–
cd ../backend/nodejs
npm install

# å®‰è£…Pythonä¾èµ–
cd ../python
pip install -r requirements.txt

# å®‰è£…AIæ¨¡å‹ä¾èµ–
cd ../../ai-models
pip install -r requirements.txt
```

### 3. æ•°æ®åº“è®¾ç½®
```bash
# åˆ›å»ºæ•°æ®åº“
createdb dota2_analyzer

# è¿è¡ŒNode.jsåç«¯è¿ç§»
cd ../backend/nodejs
npm run migrate

# è¿è¡ŒPythonåç«¯è¿ç§»
cd ../python
python manage.py migrate

# å¯¼å…¥åˆå§‹æ•°æ®
npm run seed
```

### 4. é…ç½®ç¯å¢ƒå˜é‡
```bash
# å‰ç«¯é…ç½®
cd ../../frontend
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®ç›¸å…³é…ç½®

# Node.jsåç«¯é…ç½®
cd ../backend/nodejs
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®æ•°æ®åº“ã€Redisç­‰é…ç½®

# Pythonåç«¯é…ç½®
cd ../python
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®æ•°æ®åº“ã€AIæ¨¡å‹ç­‰é…ç½®

# AIæ¨¡å‹é…ç½®
cd ../../ai-models
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®æ¨¡å‹è·¯å¾„ã€GPUé…ç½®ç­‰
```

### 5. ä¸‹è½½AIæ¨¡å‹
```bash
cd ai-models
python scripts/download_models.py
```

### 6. å¯åŠ¨æœåŠ¡
```bash
# å¯åŠ¨Node.jsåç«¯æœåŠ¡
cd ../backend/nodejs
npm run dev

# å¯åŠ¨Pythonåç«¯æœåŠ¡
cd ../python
python app.py

# å¯åŠ¨å‰ç«¯æœåŠ¡
cd ../../frontend
npm run dev

# å¯åŠ¨AIæ¨¡å‹æœåŠ¡
cd ../ai-models
python app.py

# å¯åŠ¨å®šæ—¶ä»»åŠ¡æœåŠ¡
cd ../backend/python
python scheduler.py
```

## Dockeréƒ¨ç½²

### 1. æ„å»ºé•œåƒ
```bash
# æ„å»ºæ‰€æœ‰æœåŠ¡é•œåƒ
docker-compose build

# æ„å»ºç‰¹å®šæœåŠ¡
docker-compose build frontend
docker-compose build backend-nodejs
docker-compose build backend-python
docker-compose build ai-models
```

### 2. å¯åŠ¨æœåŠ¡
```bash
# å¼€å‘ç¯å¢ƒ
docker-compose up -d

# ç”Ÿäº§ç¯å¢ƒ
docker-compose -f docker-compose.prod.yml up -d

# ä»…å¯åŠ¨åŸºç¡€è®¾æ–½æœåŠ¡
docker-compose -f infrastructure/docker/docker-compose.yml up -d postgres redis

# å¯åŠ¨ç‰¹å®šæœåŠ¡
docker-compose up -d frontend
docker-compose up -d backend-nodejs
docker-compose up -d backend-python
docker-compose up -d ai-models
```

### 3. åœæ­¢æœåŠ¡
```bash
# åœæ­¢æ‰€æœ‰æœåŠ¡
docker-compose down

# åœæ­¢å¹¶åˆ é™¤æ•°æ®å·
docker-compose down -v

# åœæ­¢ç‰¹å®šæœåŠ¡
docker-compose stop frontend
docker-compose stop backend-python
```

### 4. æŸ¥çœ‹æ—¥å¿—
```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker-compose logs -f

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker-compose logs -f backend-python
docker-compose logs -f ai-models

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æœ€è¿‘100è¡Œæ—¥å¿—
docker-compose logs --tail=100 ai-models
```

## äº‘éƒ¨ç½²

### AWSéƒ¨ç½²
1. åˆ›å»ºEC2å®ä¾‹ (æ¨èt3.largeæˆ–æ›´é«˜é…ç½®)
2. é…ç½®å®‰å…¨ç»„ (å¼€æ”¾ç«¯å£: 80, 443, 5000, 3001)
3. å®‰è£…Dockerå’ŒDocker Compose
4. å…‹éš†é¡¹ç›®ä»£ç 
5. é…ç½®ç¯å¢ƒå˜é‡
6. è¿è¡Œéƒ¨ç½²è„šæœ¬

```bash
# AWSéƒ¨ç½²è„šæœ¬
#!/bin/bash
yum update -y
yum install -y docker docker-compose git
service docker start
usermod -a -G docker ec2-user

# å…‹éš†ä»£ç 
git clone <repository-url>
cd dota2-analyzer

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶

# å¯åŠ¨æœåŠ¡
docker-compose -f docker-compose.prod.yml up -d
```

### é˜¿é‡Œäº‘éƒ¨ç½²
1. åˆ›å»ºECSå®ä¾‹ (æ¨èecs.c5.largeæˆ–æ›´é«˜é…ç½®)
2. é…ç½®å®‰å…¨ç»„è§„åˆ™
3. å®‰è£…Dockerå’ŒDocker Compose
4. å…‹éš†é¡¹ç›®ä»£ç 
5. é…ç½®ç¯å¢ƒå˜é‡
6. è¿è¡Œéƒ¨ç½²è„šæœ¬

```bash
# é˜¿é‡Œäº‘éƒ¨ç½²è„šæœ¬
#!/bin/bash
yum update -y
yum install -y docker docker-compose git
systemctl start docker
systemctl enable docker

# å…‹éš†ä»£ç 
git clone <repository-url>
cd dota2-analyzer

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶

# å¯åŠ¨æœåŠ¡
docker-compose -f docker-compose.prod.yml up -d
```

### è…¾è®¯äº‘éƒ¨ç½²
1. åˆ›å»ºCVMå®ä¾‹ (æ¨èæ ‡å‡†å‹S4æˆ–æ›´é«˜é…ç½®)
2. é…ç½®å®‰å…¨ç»„è§„åˆ™
3. å®‰è£…Dockerå’ŒDocker Compose
4. å…‹éš†é¡¹ç›®ä»£ç 
5. é…ç½®ç¯å¢ƒå˜é‡
6. è¿è¡Œéƒ¨ç½²è„šæœ¬

```bash
# è…¾è®¯äº‘éƒ¨ç½²è„šæœ¬
#!/bin/bash
apt-get update
apt-get install -y docker.io docker-compose git
systemctl start docker
systemctl enable docker

# å…‹éš†ä»£ç 
git clone <repository-url>
cd dota2-analyzer

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶

# å¯åŠ¨æœåŠ¡
docker-compose -f docker-compose.prod.yml up -d
```

### äº‘æ•°æ®åº“é…ç½®
```bash
# åˆ›å»ºRDSå®ä¾‹ (PostgreSQL 14+)
# é…ç½®æ•°æ®åº“å‚æ•°
max_connections = 200
shared_buffers = 256MB
effective_cache_size = 1GB

# åˆ›å»ºRediså®ä¾‹
# é…ç½®Rediså‚æ•°
maxmemory = 1GB
maxmemory-policy = allkeys-lru
```

## Kuberneteséƒ¨ç½²

### 1. åˆ›å»ºå‘½åç©ºé—´
```bash
kubectl create namespace dota2-analyzer
kubectl config set-context --current --namespace=dota2-analyzer
```

### 2. åˆ›å»ºConfigMapå’ŒSecret
```bash
# åˆ›å»ºé…ç½®æ–‡ä»¶
kubectl create configmap app-config --from-file=config/app.yaml
kubectl create configmap nginx-config --from-file=config/nginx.conf

# åˆ›å»ºå¯†é’¥æ–‡ä»¶
kubectl create secret generic app-secrets \
  --from-literal=database-url=postgresql://user:pass@postgres:5432/dota2_analyzer \
  --from-literal=redis-url=redis://redis:6379/0 \
  --from-literal=jwt-secret=your-jwt-secret-key \
  --from-literal=steam-api-key=your-steam-api-key
```

### 3. åº”ç”¨éƒ¨ç½²é…ç½®
```bash
# éƒ¨ç½²åŸºç¡€è®¾æ–½
kubectl apply -f infrastructure/kubernetes/postgres/
kubectl apply -f infrastructure/kubernetes/redis/

# éƒ¨ç½²åº”ç”¨æœåŠ¡
kubectl apply -f infrastructure/kubernetes/frontend/
kubectl apply -f infrastructure/kubernetes/backend-nodejs/
kubectl apply -f infrastructure/kubernetes/backend-python/
kubectl apply -f infrastructure/kubernetes/ai-models/

# éƒ¨ç½²è´Ÿè½½å‡è¡¡å™¨
kubectl apply -f infrastructure/kubernetes/nginx/
kubectl apply -f infrastructure/kubernetes/ingress/
```

### 4. æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
```bash
# æŸ¥çœ‹PodçŠ¶æ€
kubectl get pods -n dota2-analyzer
kubectl get services -n dota2-analyzer
kubectl get ingress -n dota2-analyzer

# æŸ¥çœ‹éƒ¨ç½²è¯¦æƒ…
kubectl describe deployment backend-python -n dota2-analyzer
kubectl describe service frontend -n dota2-analyzer

# æŸ¥çœ‹æ—¥å¿—
kubectl logs -f deployment/backend-python -n dota2-analyzer
kubectl logs -f deployment/ai-models -n dota2-analyzer
```

### 5. æ‰©å±•å’Œæ›´æ–°
```bash
# æ‰©å±•å‰¯æœ¬æ•°
kubectl scale deployment backend-python --replicas=3 -n dota2-analyzer
kubectl scale deployment ai-models --replicas=2 -n dota2-analyzer

# æ»šåŠ¨æ›´æ–°
kubectl set image deployment/backend-python backend-python=myrepo/dota2-python-backend:v2.0 -n dota2-analyzer
kubectl rollout status deployment/backend-python -n dota2-analyzer

# å›æ»šæ›´æ–°
kubectl rollout undo deployment/backend-python -n dota2-analyzer
```

### 6. èµ„æºé™åˆ¶é…ç½®
```yaml
# ç¤ºä¾‹ï¼šèµ„æºé™åˆ¶é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-models
spec:
  template:
    spec:
      containers:
      - name: ai-models
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
          # GPUé…ç½® (å¦‚éœ€è¦)
          nvidia.com/gpu: 1
```

### 3. é…ç½®Ingress
```bash
# å®‰è£…nginx-ingress
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml

# åº”ç”¨Ingressé…ç½®
kubectl apply -f infrastructure/kubernetes/ingress.yaml
```

## SSLè¯ä¹¦é…ç½®

### 1. Let's Encryptè¯ä¹¦
```bash
# ä½¿ç”¨cert-manager
kubectl apply -f infrastructure/kubernetes/cert-manager/
```

### 2. é˜¿é‡Œäº‘SSLè¯ä¹¦
```bash
# åœ¨é˜¿é‡Œäº‘SSLè¯ä¹¦æœåŠ¡ç”³è¯·è¯ä¹¦
# ä¸‹è½½è¯ä¹¦æ–‡ä»¶åˆ° infrastructure/ssl/
```

## ç›‘æ§å’Œæ—¥å¿—

### Prometheusç›‘æ§
```bash
# æ·»åŠ Prometheusä»“åº“
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# å®‰è£…Prometheuså’ŒGrafana
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace

# é…ç½®è‡ªå®šä¹‰ç›‘æ§è§„åˆ™
kubectl apply -f infrastructure/monitoring/prometheus-rules.yaml

# è®¿é—®Grafana
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# é»˜è®¤ç”¨æˆ·å: admin, å¯†ç : prom-operator
```

### ELK Stackæ—¥å¿—æ”¶é›†
```bash
# æ·»åŠ Elasticä»“åº“
helm repo add elastic https://helm.elastic.co
helm repo update

# å®‰è£…Elasticsearch
helm install elasticsearch elastic/elasticsearch \
  --namespace logging --create-namespace \
  --set replicas=1,minimumMasterNodes=1

# å®‰è£…Kibana
helm install kibana elastic/kibana \
  --namespace logging \
  --set service.type=LoadBalancer

# å®‰è£…Filebeat
helm install filebeat elastic/filebeat \
  --namespace logging \
  --set daemonset.enabled=true

# è®¿é—®Kibana
kubectl get svc -n logging kibana-kibana
# ä½¿ç”¨EXTERNAL-IPè®¿é—®Kibana
```

### åº”ç”¨æ€§èƒ½ç›‘æ§
```bash
# å®‰è£…Jaeger (åˆ†å¸ƒå¼è¿½è¸ª)
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
helm install jaeger jaegertracing/jaeger \
  --namespace monitoring

# å®‰è£…åº”ç”¨æŒ‡æ ‡æ”¶é›†å™¨
kubectl apply -f infrastructure/monitoring/app-metrics.yaml
```

### å‘Šè­¦é…ç½®
```yaml
# ç¤ºä¾‹ï¼šå‘Šè­¦è§„åˆ™é…ç½®
groups:
- name: dota2-analyzer
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is above 10% for 5 minutes"
  
  - alert: HighMemoryUsage
    expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage"
      description: "Memory usage is above 90%"
```

## å¤‡ä»½ç­–ç•¥

### æ•°æ®åº“å¤‡ä»½
```bash
#!/bin/bash
# æ•°æ®åº“å¤‡ä»½è„šæœ¬
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/opt/backups"
RETENTION_DAYS=30

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# PostgreSQLå¤‡ä»½
pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME > $BACKUP_DIR/postgres_backup_$DATE.sql

# å‹ç¼©å¤‡ä»½æ–‡ä»¶
gzip $BACKUP_DIR/postgres_backup_$DATE.sql

# ä¸Šä¼ åˆ°AWS S3
aws s3 cp $BACKUP_DIR/postgres_backup_$DATE.sql.gz s3://your-backup-bucket/postgres/

# ä¸Šä¼ åˆ°é˜¿é‡Œäº‘OSS
ossutil cp $BACKUP_DIR/postgres_backup_$DATE.sql.gz oss://your-backup-bucket/postgres/

# åˆ é™¤æœ¬åœ°è¿‡æœŸå¤‡ä»½
find $BACKUP_DIR -name "postgres_backup_*.sql.gz" -mtime +$RETENTION_DAYS -delete

# è®°å½•å¤‡ä»½æ—¥å¿—
echo "$(date): Database backup completed" >> /var/log/backup.log
```

### åº”ç”¨æ•°æ®å¤‡ä»½
```bash
#!/bin/bash
# åº”ç”¨æ•°æ®å¤‡ä»½è„šæœ¬
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/opt/backups"
APP_DATA_DIR="/app/data"

# åˆ›å»ºåº”ç”¨æ•°æ®å¤‡ä»½
tar -czf $BACKUP_DIR/app_data_$DATE.tar.gz $APP_DATA_DIR

# ä¸Šä¼ å¤‡ä»½åˆ°äº‘å­˜å‚¨
aws s3 cp $BACKUP_DIR/app_data_$DATE.tar.gz s3://your-backup-bucket/app-data/

# æ¸…ç†è¿‡æœŸå¤‡ä»½
find $BACKUP_DIR -name "app_data_*.tar.gz" -mtime +$RETENTION_DAYS -delete
```

### AIæ¨¡å‹å¤‡ä»½
```bash
#!/bin/bash
# AIæ¨¡å‹å¤‡ä»½è„šæœ¬
DATE=$(date +%Y%m%d_%H%M%S)
MODEL_DIR="/app/models"
BACKUP_DIR="/opt/backups"

# åˆ›å»ºæ¨¡å‹å¤‡ä»½
tar -czf $BACKUP_DIR/ai_models_$DATE.tar.gz $MODEL_DIR

# ä¸Šä¼ æ¨¡å‹å¤‡ä»½
aws s3 cp $BACKUP_DIR/ai_models_$DATE.tar.gz s3://your-backup-bucket/models/

# è®°å½•æ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯
echo "Model backup: $DATE" >> $BACKUP_DIR/model_versions.log
```

### è®¾ç½®å®šæ—¶ä»»åŠ¡
```bash
# ç¼–è¾‘crontab
crontab -e

# æ·»åŠ å®šæ—¶ä»»åŠ¡
# æ•°æ®åº“å¤‡ä»½ - æ¯å¤©å‡Œæ™¨2ç‚¹
0 2 * * * /opt/scripts/db_backup.sh

# åº”ç”¨æ•°æ®å¤‡ä»½ - æ¯å¤©å‡Œæ™¨3ç‚¹
0 3 * * * /opt/scripts/app_backup.sh

# AIæ¨¡å‹å¤‡ä»½ - æ¯å‘¨æ—¥å‡Œæ™¨4ç‚¹
0 4 * * 0 /opt/scripts/model_backup.sh

# å¤‡ä»½éªŒè¯ - æ¯å¤©å‡Œæ™¨5ç‚¹
0 5 * * * /opt/scripts/verify_backups.sh
```

### å¤‡ä»½ç›‘æ§å’Œå‘Šè­¦
```bash
#!/bin/bash
# å¤‡ä»½éªŒè¯è„šæœ¬
BACKUP_DIR="/opt/backups"
LOG_FILE="/var/log/backup-verify.log"

# æ£€æŸ¥æœ€æ–°å¤‡ä»½æ–‡ä»¶
latest_backup=$(find $BACKUP_DIR -name "postgres_backup_*.sql.gz" -mtime -1)

if [ -z "$latest_backup" ]; then
    echo "$(date): ERROR - No recent backup found" >> $LOG_FILE
    # å‘é€å‘Šè­¦
    curl -X POST "$WEBHOOK_URL" -H "Content-Type: application/json" \
        -d '{"text": "ğŸš¨ Backup verification failed - No recent backup found"}'
else
    echo "$(date): SUCCESS - Backup verification passed" >> $LOG_FILE
fi

# æ£€æŸ¥ç£ç›˜ç©ºé—´
disk_usage=$(df -h $BACKUP_DIR | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $disk_usage -gt 80 ]; then
    echo "$(date): WARNING - Backup disk usage: ${disk_usage}%" >> $LOG_FILE
fi
```

## æ€§èƒ½ä¼˜åŒ–

### 1. CDNé…ç½®
- ä½¿ç”¨é˜¿é‡Œäº‘CDNæˆ–è…¾è®¯äº‘CDN
- é…ç½®é™æ€èµ„æºç¼“å­˜ç­–ç•¥

### 2. æ•°æ®åº“ä¼˜åŒ–
```sql
-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_matches_start_time ON matches(start_time);
CREATE INDEX idx_comments_match_id ON comments(match_id);
CREATE INDEX idx_comments_user_id ON comments(user_id);
```

### 3. Redisç¼“å­˜ç­–ç•¥
```bash
# è®¾ç½®åˆç†çš„TTL
redis-cli CONFIG SET maxmemory 1gb
redis-cli CONFIG SET maxmemory-policy allkeys-lru
```

## AIæ¨¡å‹éƒ¨ç½²

### æ¨¡å‹ä¸‹è½½å’Œé…ç½®
```bash
#!/bin/bash
# AIæ¨¡å‹ä¸‹è½½è„šæœ¬
MODEL_DIR="/app/models"
MODEL_VERSION="v2.1.0"

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p $MODEL_DIR

# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
echo "Downloading AI models..."
wget -O $MODEL_DIR/dota_strategy_model.pb "https://models.dota2-analyzer.com/strategy-model-$MODEL_VERSION.pb"
wget -O $MODEL_DIR/draft_predictor.pkl "https://models.dota2-analyzer.com/draft-predictor-$MODEL_VERSION.pkl"
wget -O $MODEL_DIR/match_analyzer.onnx "https://models.dota2-analyzer.com/match-analyzer-$MODEL_VERSION.onnx"

# éªŒè¯æ¨¡å‹æ–‡ä»¶
for model in $MODEL_DIR/*; do
    if [ -f "$model" ]; then
        echo "âœ“ $(basename $model) downloaded successfully"
    else
        echo "âœ— $(basename $model) download failed"
    fi
done

# è®¾ç½®æ¨¡å‹æƒé™
chmod 644 $MODEL_DIR/*
```

### GPUé…ç½®
```bash
# NVIDIA GPUé©±åŠ¨å®‰è£…
sudo apt-get update
sudo apt-get install -y nvidia-driver-470 nvidia-dkms-470

# NVIDIA Dockeræ”¯æŒ
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker

# éªŒè¯GPUæ”¯æŒ
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```

### æ¨¡å‹æœåŠ¡é…ç½®
```yaml
# docker-compose.ymlä¸­çš„AIæ¨¡å‹æœåŠ¡é…ç½®
services:
  ai-models:
    build: ./ai-models
    environment:
      - MODEL_PATH=/app/models
      - GPU_ENABLED=true
      - GPU_MEMORY_LIMIT=4096
      - BATCH_SIZE=32
      - MAX_WORKERS=4
    volumes:
      - ./models:/app/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## æ•…éšœæ’æŸ¥

### 1. æŸ¥çœ‹æ—¥å¿—
```bash
# Dockeræ—¥å¿—
docker logs [container-name]
docker logs -f --tail=100 [container-id]

# Kubernetesæ—¥å¿—
kubectl logs -f [pod-name] -n dota2-analyzer
kubectl logs -f deployment/backend-python -n dota2-analyzer
kubectl logs -f deployment/ai-models -n dota2-analyzer --tail=200

# ç³»ç»Ÿæ—¥å¿—
journalctl -u docker.service -f
tail -f /var/log/syslog | grep -i error
```

### 2. å¥åº·æ£€æŸ¥
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:3001/health

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
kubectl exec -it [postgres-pod] -- psql -U dota2_user -d dota2_analyzer -c "SELECT 1"
```

### 3. æ€§èƒ½ç›‘æ§
- ä½¿ç”¨Prometheus + Grafana
- è®¾ç½®å…³é”®æŒ‡æ ‡å‘Šè­¦
- ç›‘æ§APIå“åº”æ—¶é—´å’Œé”™è¯¯ç‡

### 4. å¸¸è§é—®é¢˜
1. **æ•°æ®åº“è¿æ¥å¤±è´¥**
   - æ£€æŸ¥æ•°æ®åº“é…ç½®
   - éªŒè¯ç½‘ç»œè¿æ¥
   - æŸ¥çœ‹æ•°æ®åº“æ—¥å¿—
   - æ£€æŸ¥è¿æ¥æ± é…ç½®

2. **Redisè¿æ¥å¤±è´¥**
   - æ£€æŸ¥Redisé…ç½®
   - éªŒè¯ç«¯å£æ˜¯å¦å¼€æ”¾
   - é‡å¯RedisæœåŠ¡
   - æ£€æŸ¥Rediså†…å­˜ä½¿ç”¨

3. **å‰ç«¯æ„å»ºå¤±è´¥**
   - æ£€æŸ¥Node.jsç‰ˆæœ¬
   - æ¸…ç†npmç¼“å­˜
   - é‡æ–°å®‰è£…ä¾èµ–
   - æ£€æŸ¥å†…å­˜é™åˆ¶

4. **AIæ¨¡å‹åŠ è½½å¤±è´¥**
   - æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
   - éªŒè¯æ¨¡å‹æ–‡ä»¶æƒé™
   - æ£€æŸ¥GPUé©±åŠ¨å’ŒCUDAç‰ˆæœ¬
   - æŸ¥çœ‹æ¨¡å‹æœåŠ¡æ—¥å¿—

5. **Pythonåç«¯å¯åŠ¨å¤±è´¥**
   - æ£€æŸ¥Pythonç‰ˆæœ¬å’Œä¾èµ–
   - éªŒè¯æ•°æ®åº“è¿æ¥
   - æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®
   - æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—

### 5. æ€§èƒ½è°ƒä¼˜
```bash
# æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–
# 1. è¿æ¥æ± ä¼˜åŒ–
# 2. ç´¢å¼•ä¼˜åŒ–
# 3. æŸ¥è¯¢ä¼˜åŒ–

# Redisæ€§èƒ½ä¼˜åŒ–
# 1. å†…å­˜ä¼˜åŒ–
# 2. æŒä¹…åŒ–é…ç½®
# 3. é›†ç¾¤é…ç½®

# åº”ç”¨æ€§èƒ½ä¼˜åŒ–
# 1. è´Ÿè½½å‡è¡¡é…ç½®
# 2. ç¼“å­˜ç­–ç•¥
# 3. å¼‚æ­¥å¤„ç†
```

### 6. è·å–å¸®åŠ©
- æŸ¥çœ‹æ—¥å¿—: `docker-compose logs -f [service-name]`
- æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€: `docker system df`
- æŸ¥çœ‹èµ„æºä½¿ç”¨: `docker stats`
- è”ç³»æ”¯æŒ: support@dota2-analyzer.com

## å®‰å…¨å»ºè®®

### 1. ç½‘ç»œå®‰å…¨
- ä½¿ç”¨HTTPS
- é…ç½®é˜²ç«å¢™è§„åˆ™
- é™åˆ¶æ•°æ®åº“è®¿é—®IP

### 2. åº”ç”¨å®‰å…¨
- å®šæœŸæ›´æ–°ä¾èµ–
- ä½¿ç”¨Helmet.js
- è¾“å…¥éªŒè¯å’ŒSQLæ³¨å…¥é˜²æŠ¤

### 3. è®¿é—®æ§åˆ¶
- å®æ–½RBAC
- ä½¿ç”¨æœ€å°æƒé™åŸåˆ™
- å®šæœŸå®¡è®¡ç”¨æˆ·æƒé™

## æ‰©å±•éƒ¨ç½²

### 1. æ°´å¹³æ‰©å±•
```bash
# æ‰©å±•åç«¯å‰¯æœ¬
kubectl scale deployment dota2-backend --replicas=3 -n dota2-analytics

# æ‰©å±•å‰ç«¯å‰¯æœ¬
kubectl scale deployment dota2-frontend --replicas=2 -n dota2-analytics
```

### 2. è‡ªåŠ¨æ‰©ç¼©å®¹
```bash
# é…ç½®HPA
kubectl apply -f infrastructure/kubernetes/hpa.yaml
```

### 3. æ•°æ®åº“è¯»å†™åˆ†ç¦»
- ä½¿ç”¨PostgreSQLä¸»ä»å¤åˆ¶
- é…ç½®è¯»å†™åˆ†ç¦»ä¸­é—´ä»¶
- ä½¿ç”¨è¿æ¥æ± ä¼˜åŒ–æ€§èƒ½