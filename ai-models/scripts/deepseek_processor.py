#!/usr/bin/env python3
"""
DeepSeek å¾®è°ƒæ•°æ®å¤„ç†å™¨
å°†è®­ç»ƒæ•°æ®è½¬æ¢ä¸ºDeepSeek APIæ ¼å¼
"""

import json
import os
from typing import Dict, List, Any
from datetime import datetime

class DeepSeekDataProcessor:
    """DeepSeekå¾®è°ƒæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, model_name: str = "deepseek-chat"):
        """åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            model_name: ä½¿ç”¨çš„DeepSeekæ¨¡å‹åç§°
        """
        self.model_name = model_name
    
    def process_training_data(self, input_file: str, output_file: str) -> Dict[str, Any]:
        """å¤„ç†è®­ç»ƒæ•°æ®ä¸ºDeepSeekæ ¼å¼
        
        Args:
            input_file: è¾“å…¥çš„è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºçš„DeepSeekæ ¼å¼æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        """
        print(f"ğŸ“– è¯»å–è®­ç»ƒæ•°æ®: {input_file}")
        
        # è¯»å–è®­ç»ƒæ•°æ®
        with open(input_file, 'r', encoding='utf-8') as f:
            training_samples = json.load(f)
        
        print(f"ğŸ“Š å…±è¯»å– {len(training_samples)} ä¸ªè®­ç»ƒæ ·æœ¬")
        
        # è½¬æ¢ä¸ºDeepSeekæ ¼å¼
        deepseek_samples = []
        for i, sample in enumerate(training_samples):
            if i % 100 == 0:
                print(f"ğŸ”„ å¤„ç†è¿›åº¦: {i}/{len(training_samples)}")
            
            deepseek_sample = self._convert_to_deepseek_format(sample)
            if deepseek_sample:
                deepseek_samples.append(deepseek_sample)
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        self._save_deepseek_data(deepseek_samples, output_file)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_samples': len(training_samples),
            'processed_samples': len(deepseek_samples),
            'skipped_samples': len(training_samples) - len(deepseek_samples),
            'avg_input_length': sum(len(s['messages'][0]['content']) for s in deepseek_samples) / len(deepseek_samples) if deepseek_samples else 0,
            'avg_output_length': sum(len(s['messages'][1]['content']) for s in deepseek_samples) / len(deepseek_samples) if deepseek_samples else 0,
            'processing_time': datetime.now().isoformat()
        }
        
        print(f"âœ… å¤„ç†å®Œæˆ!")
        print(f"   - æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
        print(f"   - æˆåŠŸå¤„ç†: {stats['processed_samples']}")
        print(f"   - è·³è¿‡çš„æ ·æœ¬: {stats['skipped_samples']}")
        print(f"   - å¹³å‡è¾“å…¥é•¿åº¦: {stats['avg_input_length']:.0f} å­—ç¬¦")
        print(f"   - å¹³å‡è¾“å‡ºé•¿åº¦: {stats['avg_output_length']:.0f} å­—ç¬¦")
        
        return stats
    
    def _convert_to_deepseek_format(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """å°†å•ä¸ªæ ·æœ¬è½¬æ¢ä¸ºDeepSeekæ ¼å¼"""
        try:
            training_text = sample.get('training_text', '')
            match_id = sample.get('match_id', 'unknown')
            metadata = sample.get('metadata', {})
            
            # æå–å…³é”®ä¿¡æ¯ç”¨äºæ„å»ºæç¤º
            lines = training_text.split('\n')
            
            # æ„å»ºç”¨æˆ·æç¤º (é—®é¢˜)
            user_prompt = self._build_user_prompt(training_text, match_id, metadata)
            
            # æ„å»ºåŠ©æ‰‹å›å¤ (ç­”æ¡ˆ)
            assistant_response = self._build_assistant_response(training_text, match_id, metadata)
            
            # æ„å»ºDeepSeekæ ¼å¼çš„å¯¹è¯
            deepseek_sample = {
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ€å¡”2æ¯”èµ›åˆ†æå¸ˆå’Œæ™ºèƒ½åŠ©æ‰‹ã€‚ä½ å°†åŸºäºæ¯”èµ›æ•°æ®ã€ç¤¾åŒºè®¨è®ºå’Œæˆ˜æœ¯åˆ†æï¼Œä¸ºç”¨æˆ·æä¾›æ·±åº¦çš„æ¯”èµ›æ´å¯Ÿå’Œå­¦ä¹ å»ºè®®ã€‚"
                    },
                    {
                        "role": "user", 
                        "content": user_prompt
                    },
                    {
                        "role": "assistant",
                        "content": assistant_response
                    }
                ],
                "metadata": {
                    "match_id": match_id,
                    "data_sources": metadata.get('data_sources', []),
                    "has_comments": metadata.get('has_comments', False),
                    "generated_at": metadata.get('generated_at', datetime.now().isoformat())
                }
            }
            
            return deepseek_sample
            
        except Exception as e:
            print(f"è½¬æ¢æ ·æœ¬å¤±è´¥ {sample.get('match_id', 'unknown')}: {e}")
            return None
    
    def _build_user_prompt(self, training_text: str, match_id: str, metadata: Dict[str, Any]) -> str:
        """æ„å»ºç”¨æˆ·æç¤º"""
        
        # ä»è®­ç»ƒæ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯
        lines = training_text.split('\n')
        
        # æå–åŸºç¡€ä¿¡æ¯
        duration = self._extract_info_from_text(lines, "æ¯”èµ›æ—¶é•¿")
        winner = self._extract_info_from_text(lines, "è·èƒœæ–¹")
        teams = self._extract_info_from_text(lines, "## æ¯”èµ›æ•°æ®åˆ†æ")
        
        # æ„å»ºç”¨æˆ·é—®é¢˜
        user_prompt = f"""è¯·ä½œä¸ºåˆ€å¡”2ä¸“å®¶åˆ†æå¸ˆï¼ŒåŸºäºä»¥ä¸‹æ¯”èµ›ä¿¡æ¯ä¸ºæˆ‘æä¾›æ·±åº¦åˆ†æï¼š

**æ¯”èµ›åŸºæœ¬ä¿¡æ¯ï¼š**
- æ¯”èµ›ID: {match_id}
- å¯¹é˜µåŒæ–¹: {teams}
- æ¯”èµ›æ—¶é•¿: {duration}
- è·èƒœæ–¹: {winner}
- æ•°æ®æ¥æº: {', '.join(metadata.get('data_sources', ['opendota', 'stratz', 'liquipedia', 'dem']))}

**æˆ‘çš„éœ€æ±‚ï¼š**
1. åˆ†æè¿™åœºæ¯”èµ›çš„å…³é”®æˆ˜æœ¯è¦ç‚¹
2. æŒ‡å‡ºå¯ä»¥å­¦ä¹ çš„æŠ€å·§å’Œç­–ç•¥
3. åŸºäºç¤¾åŒºè®¨è®ºæ€»ç»“ç©å®¶è§‚ç‚¹
4. æ¨èç±»ä¼¼çš„æ¯”èµ›è¿›è¡Œè¿›ä¸€æ­¥å­¦ä¹ 

è¯·æä¾›è¯¦ç»†çš„ä¸“ä¸šåˆ†æï¼ŒåŒ…æ‹¬å…·ä½“çš„æ¸¸æˆæœºåˆ¶è§£é‡Šå’Œå®æˆ˜å»ºè®®ã€‚"""
        
        return user_prompt.strip()
    
    def _build_assistant_response(self, training_text: str, match_id: str, metadata: Dict[str, Any]) -> str:
        """æ„å»ºåŠ©æ‰‹å›å¤"""
        
        # ç›´æ¥ä½¿ç”¨è®­ç»ƒæ–‡æœ¬ä½œä¸ºå›å¤ï¼Œä½†é‡æ–°æ ¼å¼åŒ–ä½¿å…¶æ›´é€‚åˆå¯¹è¯
        
        # æå–å„ä¸ªéƒ¨åˆ†
        lines = training_text.split('\n')
        
        # æ„å»ºç»“æ„åŒ–çš„å›å¤
        response = f"""æˆ‘æ¥ä¸ºä½ æ·±åº¦åˆ†æè¿™åœºç²¾å½©çš„åˆ€å¡”æ¯”èµ› #{match_id}ï¼š

## ğŸ“Š æ¯”èµ›æ¦‚å†µåˆ†æ
{self._extract_section(lines, "æ¯”èµ›æ¦‚å†µ")}

## âš”ï¸ è‹±é›„é˜µå®¹ä¸æˆ˜æœ¯åˆ†æ  
{self._extract_section(lines, "è‹±é›„åˆ†æ")}

## ğŸ’° ç»æµä¸è£…å¤‡åˆ†æ
{self._extract_section(lines, "ç»æµèµ°åŠ¿")}

## ğŸ’¬ ç¤¾åŒºè§‚ç‚¹æ€»ç»“
{self._extract_section(lines, "ç¤¾åŒºæ´å¯Ÿ")}

## ğŸ¯ å…³é”®æ´å¯Ÿä¸å­¦ä¹ è¦ç‚¹

åŸºäºæ•°æ®å’Œç¤¾åŒºè®¨è®ºï¼Œè¿™åœºæ¯”èµ›çš„æ ¸å¿ƒè¦ç‚¹ï¼š

{self._extract_section(lines, "AIç»¼åˆåˆ†æ")}

## ğŸ“š å®æˆ˜å»ºè®®

**ç«‹å³å¯åº”ç”¨çš„æŠ€å·§ï¼š**
1. å…³æ³¨è‚‰å±±çš„æ§åˆ¶æ—¶æœºï¼Œç‰¹åˆ«æ˜¯åœ¨20åˆ†é’Ÿå·¦å³çš„timing
2. æ ¸å¿ƒè‹±é›„çš„è£…å¤‡timingå¯¹å›¢æˆ˜ç»“æœæœ‰å†³å®šæ€§å½±å“
3. é«˜åœ°æ¨è¿›éœ€è¦è°¨æ…é€‰æ‹©æ—¶æœºï¼Œé¿å…è¢«åæ‰“

**è¿›é˜¶å­¦ä¹ æ–¹å‘ï¼š**
- ç ”ç©¶èŒä¸šæ¯”èµ›çš„å›¢æˆ˜ç«™ä½å’ŒæŠ€èƒ½é‡Šæ”¾é¡ºåº
- åˆ†æä¸åŒè‹±é›„çš„ç»æµæ›²çº¿å’Œè£…å¤‡é€‰æ‹©
- ç†è§£åœ°å›¾æ§åˆ¶å’Œè§†é‡å¸ƒæ§çš„é‡è¦æ€§

## ğŸ”— è¿›ä¸€æ­¥å­¦ä¹ 

{self._extract_info_from_text(lines, "ç±»ä¼¼æ¯”èµ›æ¨è")}

---
*åˆ†æåŸºäº {metadata.get('data_sources', ['å¤šæ•°æ®æº'])} æ•°æ®å’Œç¤¾åŒºè®¨è®º*"""
        
        return response.strip()
    
    def _extract_info_from_text(self, lines: List[str], keyword: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–ç‰¹å®šä¿¡æ¯"""
        for line in lines:
            if keyword in line and ':' in line:
                return line.split(':', 1)[1].strip()
        return "æš‚æ— ç›¸å…³ä¿¡æ¯"
    
    def _extract_section(self, lines: List[str], section_title: str) -> str:
        """æå–ç‰¹å®šç« èŠ‚çš„å†…å®¹"""
        try:
            start_idx = None
            end_idx = None
            
            for i, line in enumerate(lines):
                if f"## {section_title}" in line:
                    start_idx = i + 1
                elif start_idx and line.startswith("## "):
                    end_idx = i
                    break
            
            if start_idx is not None:
                if end_idx is None:
                    end_idx = len(lines)
                
                section_lines = lines[start_idx:end_idx]
                return '\n'.join(line.strip() for line in section_lines if line.strip())
            
            return "è¯¥éƒ¨åˆ†å†…å®¹æš‚ç¼º"
            
        except Exception as e:
            print(f"æå–ç« èŠ‚å¤±è´¥ {section_title}: {e}")
            return "ç« èŠ‚æå–å¤±è´¥"
    
    def _save_deepseek_data(self, samples: List[Dict[str, Any]], output_file: str):
        """ä¿å­˜DeepSeekæ ¼å¼çš„æ•°æ®"""
        try:
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            # ä¿å­˜ä¸ºJSONLæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
            if output_file.endswith('.jsonl'):
                with open(output_file, 'w', encoding='utf-8') as f:
                    for sample in samples:
                        json.dump(sample, f, ensure_ascii=False)
                        f.write('\n')
            else:
                # ä¿å­˜ä¸ºæ ‡å‡†JSONæ ¼å¼
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(samples, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ DeepSeekæ ¼å¼æ•°æ®å·²ä¿å­˜: {output_file}")
            
        except Exception as e:
            print(f"ä¿å­˜DeepSeekæ•°æ®å¤±è´¥: {e}")
            raise


def main():
    """ä¸»å‡½æ•° - æµ‹è¯•DeepSeekæ•°æ®å¤„ç†å™¨"""
    print("ğŸš€ å¯åŠ¨DeepSeekæ•°æ®å¤„ç†å™¨...")
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = DeepSeekDataProcessor(model_name="deepseek-chat")
    
    # è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„
    input_file = "c:/Users/yb/PycharmProjects/PythonProject/ai-models/data/training_samples.json"
    output_file = "c:/Users/yb/PycharmProjects/PythonProject/ai-models/data/deepseek_training_data.json"
    
    # å¤„ç†æ•°æ®
    stats = processor.process_training_data(input_file, output_file)
    
    # æ˜¾ç¤ºç¤ºä¾‹
    print("\nğŸ“‹ æ˜¾ç¤ºå¤„ç†åçš„ç¤ºä¾‹æ•°æ®:")
    print("="*60)
    
    try:
        with open(output_file, 'r', encoding='utf-8') as f:
            samples = json.load(f)
        
        if samples:
            sample = samples[0]
            print(f"æ ·æœ¬ID: {sample['metadata']['match_id']}")
            print(f"ç”¨æˆ·é—®é¢˜: {sample['messages'][1]['content'][:200]}...")
            print(f"åŠ©æ‰‹å›å¤: {sample['messages'][2]['content'][:200]}...")
            print(f"å…ƒæ•°æ®: {sample['metadata']}")
    
    except Exception as e:
        print(f"æ˜¾ç¤ºç¤ºä¾‹å¤±è´¥: {e}")
    
    print("\nâœ… DeepSeekæ•°æ®å¤„ç†å®Œæˆï¼")
    print("\nä¸‹ä¸€æ­¥:")
    print("1. ä½¿ç”¨deepseek APIä¸Šä¼ æ•°æ®è¿›è¡Œå¾®è°ƒ")
    print("2. åœ¨åº”ç”¨ä¸­é›†æˆå¾®è°ƒåçš„æ¨¡å‹")
    print("3. åˆ›å»ºæ™ºèƒ½åŠ©æ‰‹æ¥å£")


if __name__ == '__main__':
    main()